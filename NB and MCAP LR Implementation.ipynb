{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing required packages."
      ],
      "metadata": {
        "id": "Nyb77TbnCG1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb4b0gvKBRh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b153e05-04c0-4907-ed1b-527486077a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from os import listdir\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing Datasets\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Tokenising raw datasets. enron1, enron2 and enron4 will correspond to index 0, 1 and 2 going forward. "
      ],
      "metadata": {
        "id": "Beg_ZlpHCL6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_filedir = \"/content/drive/MyDrive/DATASET/enron\"\n",
        "tokenized_train_datasets = [[],[],[]]\n",
        "tokenized_test_datasets = [[],[],[]]\n",
        "\n",
        "for i in ['1', '2', '4']:\n",
        "  for txt_file in listdir(common_filedir + i + \"_train/enron\" + i + \"/train/spam/\"):\n",
        "    with open(common_filedir + i + \"_train/enron\" + i + \"/train/spam/\"+txt_file, 'r',encoding = 'unicode_escape') as file:\n",
        "      data = file.read()\n",
        "      tokenized_train_datasets[int(i)-1 if int(i) != 4 else 2].append((word_tokenize(data), 1))\n",
        "    \n",
        "\n",
        "  for txt_file in listdir(common_filedir + i + \"_train/enron\" + i + \"/train/ham/\"):  \n",
        "    with open(common_filedir + i + \"_train/enron\" + i + \"/train/ham/\"+txt_file, 'r') as file:\n",
        "      data = file.read()\n",
        "      tokenized_train_datasets[int(i)-1 if int(i) != 4 else 2].append((word_tokenize(data), 0))\n",
        "\n",
        "  for txt_file in listdir(common_filedir + i + \"_test/enron\" + i + \"/test/spam/\"):\n",
        "    with open(common_filedir + i + \"_test/enron\" + i + \"/test/spam/\"+txt_file, 'r',encoding = 'unicode_escape') as file:\n",
        "      data = file.read()\n",
        "      tokenized_test_datasets[int(i)-1 if int(i) != 4 else 2].append((word_tokenize(data), 1))\n",
        "\n",
        "  for txt_file in listdir(common_filedir + i + \"_test/enron\" + i + \"/test/ham/\"):  \n",
        "    with open(common_filedir + i + \"_test/enron\" + i + \"/test/ham/\"+txt_file, 'r') as file:\n",
        "      data = file.read()\n",
        "      tokenized_test_datasets[int(i)-1 if int(i) != 4 else 2].append((word_tokenize(data), 0))"
      ],
      "metadata": {
        "id": "gXX-SFMcElas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating separate vocabulary list based on the training datasets."
      ],
      "metadata": {
        "id": "wOBtSeDtCPGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [set(), set(), set()]\n",
        "for i, dataset in enumerate(tokenized_train_datasets):\n",
        "  for mail, category in dataset:\n",
        "    for word in mail:\n",
        "      if word not in stopwords.words('english'):\n",
        "        vocab[i].add(word)"
      ],
      "metadata": {
        "id": "-sm1lucWDGfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab[0]),len(vocab[1]),len(vocab[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-oerxHTJFZm",
        "outputId": "a06fd675-6cfb-4ba4-a49e-567e3c5a82ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9973, 10308, 17747)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving each email in dataset as count of words in a dictionary with the vocab list as keys. Using same vocab list for testing set vectorization."
      ],
      "metadata": {
        "id": "PdpsKQxfER2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_word_count_n_output = [[],[],[]]\n",
        "test_data_word_count_n_output = [[],[],[]]\n",
        "\n",
        "for i, dataset in enumerate(tokenized_train_datasets):\n",
        "  dataset_bow = []\n",
        "  for mail, category in dataset:\n",
        "    dict_vector = dict.fromkeys(vocab[i], 0)\n",
        "    for word in mail:\n",
        "      if word in vocab[i]:\n",
        "        dict_vector[word] += 1\n",
        "    \n",
        "    dataset_bow.append([dict_vector, category])\n",
        "  train_data_word_count_n_output[i] = dataset_bow\n",
        "\n",
        "for i, dataset in enumerate(tokenized_test_datasets):\n",
        "  dataset_bow = []\n",
        "  for mail, category in dataset:\n",
        "    dict_vector = dict.fromkeys(vocab[i], 0)\n",
        "    for word in mail:\n",
        "      if word in vocab[i]:\n",
        "        dict_vector[word] += 1\n",
        "    \n",
        "    dataset_bow.append([dict_vector, category])\n",
        "  test_data_word_count_n_output[i] = dataset_bow"
      ],
      "metadata": {
        "id": "HGVX1SCgMk94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(len(train_data_word_count_n_output[0][0][0].keys()),\n",
        "len(train_data_word_count_n_output[1][0][0].keys()),\n",
        "len(train_data_word_count_n_output[2][0][0].keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWHkP-3qIK3s",
        "outputId": "5abda1d5-148f-41dc-8818-8693812b8982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9973, 10308, 17747)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes\n",
        "---\n"
      ],
      "metadata": {
        "id": "2KKLcvpTEnFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prior_prob_ham = [0,0,0]\n",
        "prior_prob_spam = [0,0,0]\n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  prior_prob_spam[i] = len([1 for count_dict, category in train_data_word_count_n_output[i] if category == 1])/len(train_data_word_count_n_output[i])\n",
        "  prior_prob_ham[i] = 1 - prior_prob_spam[i]\n",
        "\n",
        "prior_count_word_ham = [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)] \n",
        "prior_count_word_spam = [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)] \n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  for word in vocab[i]:\n",
        "    for vect, cat in train_data_word_count_n_output[i]:\n",
        "      if cat == 0:\n",
        "        prior_count_word_ham[i][word] += vect[word]\n",
        "      else:\n",
        "        prior_count_word_spam[i][word] += vect[word]\n",
        "\n",
        "sum_of_words_ham = [0,0,0]\n",
        "sum_of_words_spam = [0,0,0]\n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  for word,v in prior_count_word_ham[i].items(): \n",
        "    sum_of_words_ham[i] += v\n",
        "  for word,v in prior_count_word_spam[i].items(): \n",
        "    sum_of_words_spam[i] += v\n",
        "\n",
        "prior_prob_word_ham =  [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)] \n",
        "prior_prob_word_spam = [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)]\n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  for word in vocab[i]:\n",
        "    prior_prob_word_ham[i][word] = (prior_count_word_ham[i][word]+1)/(sum_of_words_ham[i] + sum_of_words_ham[i] -prior_count_word_ham[i][word] - 1)\n",
        "    prior_prob_word_spam[i][word] = (prior_count_word_spam[i][word]+1)/(sum_of_words_spam[i] + sum_of_words_spam[i] - prior_count_word_spam[i][word]-1)\n",
        "\n",
        "correct = [0, 0, 0]\n",
        "wrong = [0, 0, 0]\n",
        "for i, tokenized_ds in enumerate(tokenized_train_datasets):\n",
        "  for mail, cat in tokenized_ds:\n",
        "    c_ham = 0\n",
        "    c_spam = 0\n",
        "    for word in mail:\n",
        "      if word in prior_prob_word_ham[i].keys():\n",
        "        c_ham += np.log(prior_prob_ham[i]) + np.log(prior_prob_word_ham[i][word])\n",
        "        c_spam += np.log(prior_prob_spam[i]) + np.log(prior_prob_word_spam[i][word])\n",
        "    if((cat ==0 and c_ham > c_spam) or (cat == 1 and c_spam >= c_ham)):\n",
        "      correct[i] += 1\n",
        "    else:\n",
        "      wrong[i] += 1\n",
        "\n",
        "  print(\"Accuracy for training Dataset\",i,\":\",correct[i]/(wrong[i]+correct[i]))\n",
        "\n",
        "correct = [0, 0, 0]\n",
        "wrong = [0, 0, 0]\n",
        "tp = [0,0,0]\n",
        "tn = [0,0,0]\n",
        "fp = [0,0,0]\n",
        "fn = [0,0,0]\n",
        "print('')\n",
        "for i, tokenized_ds in enumerate(tokenized_test_datasets):\n",
        "  for mail, cat in tokenized_ds:\n",
        "    c_ham = 0\n",
        "    c_spam = 0\n",
        "    for word in mail:\n",
        "      if word in prior_prob_word_ham[i].keys():\n",
        "        c_ham += np.log(prior_prob_ham[i]) + np.log(prior_prob_word_ham[i][word])\n",
        "        c_spam += np.log(prior_prob_spam[i]) + np.log(prior_prob_word_spam[i][word])\n",
        "    if((cat ==0 and c_ham > c_spam) or (cat == 1 and c_spam >= c_ham)):\n",
        "      correct[i] += 1\n",
        "      if(cat ==0):\n",
        "        tn[i] += 1\n",
        "      else:\n",
        "        tp[i] += 1\n",
        "    else:\n",
        "      wrong[i] += 1\n",
        "      if(cat ==0):\n",
        "        fp[i] += 1\n",
        "      else:\n",
        "        fn[i] += 1\n",
        "  print(\"\\nFor Test Dataset\",i,\":-\")\n",
        "  print(\"Accuracy:\",correct[i]/(wrong[i]+correct[i]))\n",
        "  print(\"F1:\",(2 * (tp[i]/(tp[i]+fp[i])) * (tp[i]/(tp[i]+fn[i]))) / ((tp[i]/(tp[i]+fp[i])) + (tp[i]/(tp[i]+fn[i]))))\n",
        "  print(\"Precision:\",tp[i]/(tp[i]+fp[i]))\n",
        "  print(\"Recall:\",tp[i]/(tp[i]+fn[i]))\n",
        "  "
      ],
      "metadata": {
        "id": "gDCfuzaOt7CT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932ffd58-94bf-4dbf-f11a-294c23f92895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for training Dataset 0 : 0.9088888888888889\n",
            "Accuracy for training Dataset 1 : 0.9071274298056156\n",
            "Accuracy for training Dataset 2 : 0.9401869158878504\n",
            "\n",
            "\n",
            "For Test Dataset 0 :-\n",
            "Accuracy: 0.75\n",
            "F1: 0.3804347826086956\n",
            "Precision: 1.0\n",
            "Recall: 0.2348993288590604\n",
            "\n",
            "For Test Dataset 1 :-\n",
            "Accuracy: 0.7656903765690377\n",
            "F1: 0.24324324324324326\n",
            "Precision: 1.0\n",
            "Recall: 0.13846153846153847\n",
            "\n",
            "For Test Dataset 2 :-\n",
            "Accuracy: 0.8950276243093923\n",
            "F1: 0.9320619785458879\n",
            "Precision: 0.8727678571428571\n",
            "Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discrete Naive Bayes\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UTuGsttwL_Dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import final\n",
        "from IPython.lib.display import IFrame\n",
        "prior_prob_ham = [0,0,0]\n",
        "prior_prob_spam = [0,0,0]\n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  prior_prob_spam[i] = len([1 for count_dict, category in train_data_word_count_n_output[i] if category == 1])/len(train_data_word_count_n_output[i])\n",
        "  prior_prob_ham[i] = 1 - prior_prob_spam[i]\n",
        "\n",
        "prior_count_word_ham = [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)] \n",
        "prior_count_word_spam = [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)] \n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  for word in vocab[i]:\n",
        "    for vect, cat in train_data_word_count_n_output[i]:\n",
        "      if cat == 0:\n",
        "        prior_count_word_ham[i][word] += 1 if vect[word] > 0 else 0\n",
        "      else:\n",
        "        prior_count_word_spam[i][word] += 1 if vect[word] > 0 else 0\n",
        "\n",
        "sum_of_words_ham = [0,0,0]\n",
        "sum_of_words_spam = [0,0,0]\n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  for word,v in prior_count_word_ham[i].items(): \n",
        "    sum_of_words_ham[i] += v\n",
        "  for word,v in prior_count_word_spam[i].items(): \n",
        "    sum_of_words_spam[i] += v\n",
        "\n",
        "prior_prob_word_ham =  [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)] \n",
        "prior_prob_word_spam = [dict.fromkeys(vocab[0], 0), dict.fromkeys(vocab[1], 0), dict.fromkeys(vocab[2], 0)]\n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  for word in vocab[i]:\n",
        "    prior_prob_word_ham[i][word] = (prior_count_word_ham[i][word]+1)/(sum_of_words_ham[i] + sum_of_words_ham[i] -prior_count_word_ham[i][word] - 1)\n",
        "    prior_prob_word_spam[i][word] = (prior_count_word_spam[i][word]+1)/(sum_of_words_spam[i] + sum_of_words_spam[i] - prior_count_word_spam[i][word]-1)\n",
        "\n",
        "correct = [0, 0, 0]\n",
        "wrong = [0, 0, 0]\n",
        "for i, tokenized_ds in enumerate(tokenized_train_datasets):\n",
        "  for mail, cat in tokenized_ds:\n",
        "    c_ham = 0\n",
        "    c_spam = 0\n",
        "    for word in mail:\n",
        "      if word in prior_prob_word_ham[i].keys():\n",
        "        c_ham += np.log(prior_prob_ham[i]) + np.log(prior_prob_word_ham[i][word])\n",
        "        c_spam += np.log(prior_prob_spam[i]) + np.log(prior_prob_word_spam[i][word])\n",
        "    if((cat ==0 and c_ham > c_spam) or (cat == 1 and c_spam >= c_ham)):\n",
        "      correct[i] += 1\n",
        "    else:\n",
        "      wrong[i] += 1\n",
        "\n",
        "  print(\"Accuracy for training Dataset\",i,\":\",correct[i]/(wrong[i]+correct[i]))\n",
        "\n",
        "correct = [0, 0, 0]\n",
        "wrong = [0, 0, 0]\n",
        "tp = [0,0,0]\n",
        "tn = [0,0,0]\n",
        "fp = [0,0,0]\n",
        "fn = [0,0,0]\n",
        "for i, tokenized_ds in enumerate(tokenized_test_datasets):\n",
        "  for mail, cat in tokenized_ds:\n",
        "    c_ham = 0\n",
        "    c_spam = 0\n",
        "    for word in mail:\n",
        "      if word in prior_prob_word_ham[i].keys():\n",
        "        c_ham += np.log(prior_prob_ham[i]) + np.log(prior_prob_word_ham[i][word])\n",
        "        c_spam += np.log(prior_prob_spam[i]) + np.log(prior_prob_word_spam[i][word])\n",
        "    if((cat ==0 and c_ham > c_spam) or (cat == 1 and c_spam >= c_ham)):\n",
        "      correct[i] += 1\n",
        "      if(cat ==0):\n",
        "        tn[i] += 1\n",
        "      else:\n",
        "        tp[i] += 1\n",
        "    else:\n",
        "      wrong[i] += 1\n",
        "      if(cat ==0):\n",
        "        fp[i] += 1\n",
        "      else:\n",
        "        fn[i] += 1\n",
        "\n",
        "  print(\"\\nFor Test Dataset\",i,\":-\")\n",
        "  print(\"Accuracy:\",correct[i]/(wrong[i]+correct[i]))\n",
        "  print(\"F1:\",(2 * (tp[i]/(tp[i]+fp[i])) * (tp[i]/(tp[i]+fn[i]))) / ((tp[i]/(tp[i]+fp[i])) + (tp[i]/(tp[i]+fn[i]))))\n",
        "  print(\"Precision:\",tp[i]/(tp[i]+fp[i]))\n",
        "  print(\"Recall:\",tp[i]/(tp[i]+fn[i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpSS__h4DmLL",
        "outputId": "c1e050b5-360a-4784-ca3b-93cc9fdc5546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for training Dataset 0 : 0.7733333333333333\n",
            "Accuracy for training Dataset 1 : 0.7688984881209503\n",
            "Accuracy for training Dataset 2 : 0.9757009345794393\n",
            "\n",
            "For Test Dataset 0 :-\n",
            "Accuracy: 0.6842105263157895\n",
            "F1: 0.06493506493506493\n",
            "Precision: 1.0\n",
            "Recall: 0.03355704697986577\n",
            "\n",
            "For Test Dataset 1 :-\n",
            "Accuracy: 0.7322175732217573\n",
            "F1: 0.030303030303030307\n",
            "Precision: 1.0\n",
            "Recall: 0.015384615384615385\n",
            "\n",
            "For Test Dataset 2 :-\n",
            "Accuracy: 0.9134438305709024\n",
            "F1: 0.9433051869722556\n",
            "Precision: 0.8926940639269406\n",
            "Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MCAP Logistic Regression\n",
        "\n",
        "---\n",
        "\n",
        "Making 1-D feature vector. Normalizing Bag of Words representation, so that the variables do not overflow"
      ],
      "metadata": {
        "id": "e55QLqjDOkmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "feature_vector_bow_train_datasets = [[],[],[]]\n",
        "feature_vector_bernoulli_train_datasets = [[],[],[]]\n",
        "train_data_set_op = [[],[],[]]\n",
        "\n",
        "for i, dataset in enumerate(train_data_word_count_n_output):\n",
        "  vocab_ordered = sorted(vocab[i])\n",
        "  dataset_bow_ip = []\n",
        "  dataset_bernoulli_ip = []\n",
        "  dataset_op = []\n",
        "  for data_dict, cat in dataset:\n",
        "    feature_vector_bow = []\n",
        "    feature_vector_bernoulli = []\n",
        "    for word in vocab_ordered:\n",
        "      feature_vector_bow.append(data_dict[word])\n",
        "      feature_vector_bernoulli.append(1 if data_dict[word] != 0 else 0)\n",
        "    dataset_bow_ip.append(normalize(np.array([feature_vector_bow])))\n",
        "    dataset_bernoulli_ip.append([feature_vector_bernoulli])\n",
        "    dataset_op.append(cat)\n",
        "  \n",
        "  feature_vector_bow_train_datasets[i] = dataset_bow_ip\n",
        "  feature_vector_bernoulli_train_datasets[i] = dataset_bernoulli_ip\n",
        "  train_data_set_op[i] = dataset_op\n",
        "\n",
        "\n",
        "feature_vector_bow_test_datasets = [[],[],[]]\n",
        "feature_vector_bernoulli_test_datasets = [[],[],[]]\n",
        "test_data_set_op = [[],[],[]]\n",
        "\n",
        "for i, dataset in enumerate(test_data_word_count_n_output):\n",
        "  vocab_ordered = sorted(vocab[i])\n",
        "  dataset_bow_ip = []\n",
        "  dataset_bernoulli_ip = []\n",
        "  dataset_op = []\n",
        "  for data_dict, cat in dataset:\n",
        "    feature_vector_bow = []\n",
        "    feature_vector_bernoulli = []\n",
        "    for word in vocab_ordered:\n",
        "      feature_vector_bow.append(data_dict[word])\n",
        "      feature_vector_bernoulli.append(1 if data_dict[word] != 0 else 0)\n",
        "    dataset_bow_ip.append(normalize(np.array([feature_vector_bow])))\n",
        "    dataset_bernoulli_ip.append([feature_vector_bernoulli])\n",
        "    dataset_op.append(cat)\n",
        "  \n",
        "  feature_vector_bow_test_datasets[i] = dataset_bow_ip\n",
        "  feature_vector_bernoulli_test_datasets[i] = dataset_bernoulli_ip\n",
        "  test_data_set_op[i] = dataset_op\n"
      ],
      "metadata": {
        "id": "Y3VPR0TROigi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(len(feature_vector_bow_train_datasets[2]), len(train_data_set_op[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE3uI3F8QD9T",
        "outputId": "0ae828ce-6067-4d0a-8688-91ca51e710ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(535, 535)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making converting the data into Numpy arrays for ease of calculations."
      ],
      "metadata": {
        "id": "ksBEvMjgRgjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_feature_vector_bow_train_datasets = [[],[],[]]\n",
        "np_feature_vector_bernoulli_train_datasets = [[],[],[]]\n",
        "np_train_data_set_op = [[],[],[]]\n",
        "np_feature_vector_bow_test_datasets = [[],[],[]]\n",
        "np_feature_vector_bernoulli_test_datasets = [[],[],[]]\n",
        "np_test_data_set_op = [[],[],[]]\n",
        "\n",
        "for i in range(3):\n",
        "  np_feature_vector_bow_train_datasets[i] = np.row_stack(feature_vector_bow_train_datasets[i])\n",
        "  np_feature_vector_bernoulli_train_datasets[i] = np.row_stack(feature_vector_bernoulli_train_datasets[i])\n",
        "  np_train_data_set_op[i] = np.array(train_data_set_op[i])\n",
        "  np_feature_vector_bow_test_datasets[i] = np.row_stack(feature_vector_bow_test_datasets[i])\n",
        "  np_feature_vector_bernoulli_test_datasets[i] = np.row_stack(feature_vector_bernoulli_test_datasets[i])\n",
        "  np_test_data_set_op[i] = np.array(test_data_set_op[i])\n",
        "\n",
        "print(np_feature_vector_bow_train_datasets[0].shape, np_train_data_set_op[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbhxvdSaQJwt",
        "outputId": "7d33a444-9d6e-4d2b-cbe1-71630b8ac1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(450, 9973) (450,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the weights to 0 value vector. Number of weights would be number of features + 1, where the extra one is the bias. Here a model would be nothing but the weight values. Creating separate objects to represent Bag of words and Bernoulli models separately."
      ],
      "metadata": {
        "id": "jBdTQ3yFl6S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_model = [{\"weights\":np.array([], dtype = np.float128), \"X\":np.array([]), \"y\":np.array([])},\n",
        "          {\"weights\":np.array([], dtype = np.float128), \"X\":np.array([]), \"y\":np.array([])},\n",
        "          {\"weights\":np.array([], dtype = np.float128), \"X\":np.array([]), \"y\":np.array([])}]\n",
        "\n",
        "for i in range(3):\n",
        "  bow_model[i][\"weights\"] = np.ones(len(vocab[i])+1, dtype = np.float128) \n",
        "  bow_model[i][\"X\"] = np_feature_vector_bow_train_datasets[i]\n",
        "  bow_model[i][\"y\"] = np_train_data_set_op[i]"
      ],
      "metadata": {
        "id": "eaYfkuePieTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ber_model = [{\"weights\":np.array([], dtype = np.float128), \"X\":np.array([]), \"y\":np.array([])},\n",
        "          {\"weights\":np.array([], dtype = np.float128), \"X\":np.array([]), \"y\":np.array([])},\n",
        "          {\"weights\":np.array([], dtype = np.float128), \"X\":np.array([]), \"y\":np.array([])}]\n",
        "\n",
        "for i in range(3):\n",
        "  ber_model[i][\"weights\"] = np.ones(len(vocab[i])+1, dtype = np.float128) \n",
        "  ber_model[i][\"X\"] = np_feature_vector_bernoulli_train_datasets[i]\n",
        "  ber_model[i][\"y\"] = np_train_data_set_op[i]"
      ],
      "metadata": {
        "id": "BNjQlAHyVhge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, delta,lamb):\n",
        "  Pwk = np.zeros(len(model[\"X\"]), dtype = np.float128)\n",
        "  for i, Xk in enumerate(model[\"X\"]):\n",
        "    Xk = np.append([1], Xk)\n",
        "    sum = np.dot(model[\"weights\"], Xk)\n",
        "    t1 = sum \n",
        "    t2 = np.log(1+np.exp(sum))\n",
        "    Pwk[i] = np.exp(t1 - t2)\n",
        "  \n",
        "  arg1 = np.subtract(model[\"y\"], Pwk)\n",
        "\n",
        "  for i, w in enumerate(model[\"weights\"]):\n",
        "    if i != 0:\n",
        "      dlw = np.dot(model[\"X\"][:, i-1],np.transpose(arg1))\n",
        "    else:\n",
        "      dlw = np.sum(arg1)\n",
        "    old = model[\"weights\"][i]\n",
        "    regularisation_term = np.array([delta],dtype = np.float128)*np.array([lamb],dtype = np.float128)*np.array([old],dtype = np.float128)*np.array([old],dtype = np.float128)\n",
        "    model[\"weights\"][i] += np.array([delta*dlw],dtype = np.float128) - regularisation_term\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "8LfKP4uIpW0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_for_lasso(model, X, y, delta, lamb):\n",
        "  Pwk = np.zeros(len(X), dtype = np.float128)\n",
        "  for i, Xk in enumerate(X):\n",
        "    Xk = np.append([1], Xk)\n",
        "    sum = np.dot(model[\"weights\"], Xk)\n",
        "    t1 = sum \n",
        "    t2 = np.log(1+np.exp(sum))\n",
        "    Pwk[i] = np.exp(t1 - t2)\n",
        "  \n",
        "  arg1 = np.subtract(y, Pwk)\n",
        "\n",
        "  for i, w in enumerate(model[\"weights\"]):\n",
        "    if i != 0:\n",
        "      dlw = np.dot(X[:, i-1],np.transpose(arg1))\n",
        "    else:\n",
        "      dlw = np.sum(arg1)\n",
        "\n",
        "    old = model[\"weights\"][i]\n",
        "    regularisation_term = np.array([delta],dtype = np.float128)*np.array([lamb],dtype = np.float128)*np.array([old],dtype = np.float128)*np.array([old],dtype = np.float128)\n",
        "    model[\"weights\"][i] += delta*dlw - regularisation_term\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "i6t9r7d2vL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X, y):\n",
        "  correct, wrong = 0,0\n",
        "  for i, Xk in enumerate(X):\n",
        "    Xk = np.append([1], Xk)\n",
        "    sum = np.dot(model[\"weights\"], Xk)\n",
        "    t1 = sum \n",
        "    t2 = np.log(1+np.exp(sum))\n",
        "    p = np.exp(t1 - t2)\n",
        "\n",
        "    if(p > 0.5 and y[i] == 1) or (p <= 0.5 and y[i] == 0): \n",
        "      correct += 1\n",
        "    else:\n",
        "      wrong += 1\n",
        "  return correct/(correct+wrong)"
      ],
      "metadata": {
        "id": "cIisZ_Eo_VK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "for i in range(3):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(bow_model[i][\"X\"], bow_model[i][\"y\"], test_size=0.30, random_state=1)\n",
        "  bow_model_lasso =  bow_model[i]  \n",
        "  lambda_n_acc_diff = []\n",
        "  for l in range(0,11):\n",
        "    bow_model_lasso = copy.deepcopy(bow_model[i])\n",
        "    for iter in range(75):\n",
        "      if iter%5 == 0:\n",
        "        print(iter, end = ' ')\n",
        "      bow_model_lasso = fit_for_lasso(bow_model_lasso, X_train, y_train, 0.01,l/10)\n",
        "    print('')\n",
        "    acc_tr = predict(bow_model_lasso, X_train, y_train)\n",
        "    acc_ts = predict(bow_model_lasso, X_test, y_test)\n",
        "    print(\"\\n\",acc_tr, acc_ts, abs(acc_tr-acc_ts), l/10)\n",
        "    lambda_n_acc_diff.append([abs(acc_tr-acc_ts), l/10])\n",
        "  print(\"Best lambda for model\",i,\":\", min(lambda_n_acc_diff))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u-rsnGevtQZ",
        "outputId": "d3904ac6-a1ab-4124-a33f-ff774a9c25d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8571428571428571 0.8444444444444444 0.012698412698412653 0.0\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8539682539682539 0.8518518518518519 0.002116402116402072 0.1\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8539682539682539 0.8592592592592593 0.005291005291005346 0.2\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8507936507936508 0.8592592592592593 0.00846560846560851 0.3\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8380952380952381 0.8592592592592593 0.021164021164021163 0.4\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8412698412698413 0.8592592592592593 0.017989417989418 0.5\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8253968253968254 0.8592592592592593 0.03386243386243393 0.6\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.7936507936507936 0.8518518518518519 0.05820105820105825 0.7\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.7968253968253968 0.8518518518518519 0.05502645502645509 0.8\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8031746031746032 0.8518518518518519 0.04867724867724865 0.9\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.7841269841269841 0.8296296296296296 0.04550264550264549 1.0\n",
            "Best lambda for model 0 : [0.002116402116402072, 0.1]\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8425925925925926 0.8345323741007195 0.008060218491873106 0.0\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8271604938271605 0.8345323741007195 0.007371880273558951 0.1\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8271604938271605 0.8345323741007195 0.007371880273558951 0.2\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.845679012345679 0.841726618705036 0.003952393640643037 0.3\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8364197530864198 0.841726618705036 0.005306865618616152 0.4\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8240740740740741 0.8201438848920863 0.003930189181987731 0.5\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.808641975308642 0.8273381294964028 0.018696154187760827 0.6\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.7901234567901234 0.8129496402877698 0.022826183497646424 0.7\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.7839506172839507 0.7985611510791367 0.014610533795186065 0.8\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.7777777777777778 0.7841726618705036 0.006394884092725817 0.9\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.7376543209876543 0.7482014388489209 0.010547117861266608 1.0\n",
            "Best lambda for model 1 : [0.003930189181987731, 0.5]\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8422459893048129 0.8633540372670807 0.02110804796226784 0.0\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8449197860962567 0.8571428571428571 0.012223071046600364 0.1\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8502673796791443 0.8695652173913043 0.019297837712159982 0.2\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8502673796791443 0.8757763975155279 0.025509017836383596 0.3\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8449197860962567 0.8757763975155279 0.030856611419271207 0.4\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8449197860962567 0.8757763975155279 0.030856611419271207 0.5\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8502673796791443 0.8757763975155279 0.025509017836383596 0.6\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8502673796791443 0.8695652173913043 0.019297837712159982 0.7\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8529411764705882 0.8695652173913043 0.01662404092071612 0.8\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8556149732620321 0.8695652173913043 0.01395024412927226 0.9\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.8556149732620321 0.8695652173913043 0.01395024412927226 1.0\n",
            "Best lambda for model 2 : [0.012223071046600364, 0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_vals = [0.1, 0.5, 0.1]\n",
        "for i, model in enumerate(bow_model):\n",
        "  print(\"--------Model \"+str(i)+\"---------\")\n",
        "  for iter in range(1, 201):\n",
        "    bow_model[i] = fit(model, 0.01,lambda_vals[i])\n",
        "\n",
        "    if(iter%50 == 0):\n",
        "      acc1 = predict(model, model[\"X\"], model[\"y\"])\n",
        "      acc2 = predict(model, np_feature_vector_bow_test_datasets[i], np_test_data_set_op[i])\n",
        "      print(\"Iterations Done:\", iter, end = '\\t')\n",
        "      print(\"Train Accuracy Dataset\", i, \":\", acc1, end = '\\t')\n",
        "      print(\"Test Accuracy Dataset\", i, \":\", acc2)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skdKL6zE68zU",
        "outputId": "4a06e6b4-c318-46da-db45-79ad8be7f08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------Model 0---------\n",
            "Iterations Done: 50\tTrain Accuracy Dataset 0 : 0.84\tTest Accuracy Dataset 0 : 0.7390350877192983\n",
            "Iterations Done: 100\tTrain Accuracy Dataset 0 : 0.9066666666666666\tTest Accuracy Dataset 0 : 0.7697368421052632\n",
            "Iterations Done: 150\tTrain Accuracy Dataset 0 : 0.9311111111111111\tTest Accuracy Dataset 0 : 0.8070175438596491\n",
            "Iterations Done: 200\tTrain Accuracy Dataset 0 : 0.94\tTest Accuracy Dataset 0 : 0.8157894736842105\n",
            "--------Model 1---------\n",
            "Iterations Done: 50\tTrain Accuracy Dataset 1 : 0.8358531317494601\tTest Accuracy Dataset 1 : 0.7615062761506276\n",
            "Iterations Done: 100\tTrain Accuracy Dataset 1 : 0.8855291576673866\tTest Accuracy Dataset 1 : 0.7866108786610879\n",
            "Iterations Done: 150\tTrain Accuracy Dataset 1 : 0.9222462203023758\tTest Accuracy Dataset 1 : 0.8075313807531381\n",
            "Iterations Done: 200\tTrain Accuracy Dataset 1 : 0.9265658747300216\tTest Accuracy Dataset 1 : 0.8368200836820083\n",
            "--------Model 2---------\n",
            "Iterations Done: 50\tTrain Accuracy Dataset 2 : 0.8542056074766355\tTest Accuracy Dataset 2 : 0.8213627992633518\n",
            "Iterations Done: 100\tTrain Accuracy Dataset 2 : 0.8728971962616823\tTest Accuracy Dataset 2 : 0.852670349907919\n",
            "Iterations Done: 150\tTrain Accuracy Dataset 2 : 0.908411214953271\tTest Accuracy Dataset 2 : 0.8747697974217311\n",
            "Iterations Done: 200\tTrain Accuracy Dataset 2 : 0.9271028037383178\tTest Accuracy Dataset 2 : 0.8858195211786372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "for i in range(3):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(ber_model[i][\"X\"], ber_model[i][\"y\"], test_size=0.30, random_state=1)\n",
        "  ber_model_lasso =  ber_model[i]  \n",
        "  lambda_n_acc_diff = []\n",
        "  for l in range(0,10):\n",
        "    ber_model_lasso = copy.deepcopy(ber_model[i])\n",
        "    for iter in range(75):\n",
        "      if iter%5 == 0:\n",
        "        print(iter, end = ' ')\n",
        "      ber_model_lasso = fit_for_lasso(ber_model_lasso, X_train, y_train, 0.01,l/100)\n",
        "    print('')\n",
        "    acc_tr = predict(ber_model_lasso, X_train, y_train)\n",
        "    acc_ts = predict(ber_model_lasso, X_test, y_test)\n",
        "    print(\"\\n\",acc_tr, acc_ts, abs(acc_tr-acc_ts), l/100)\n",
        "    lambda_n_acc_diff.append([abs(acc_tr-acc_ts), l/100])\n",
        "  print(\"Best lambda for model\",i,\":\", min(lambda_n_acc_diff))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIfPNp7LV1aE",
        "outputId": "25916ba9-7e0a-4246-a83f-22dd2fc7ff45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8740740740740741 0.12275132275132272 0.0\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8740740740740741 0.12275132275132272 0.01\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8740740740740741 0.12275132275132272 0.02\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8740740740740741 0.12275132275132272 0.03\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8814814814814815 0.1153439153439153 0.04\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8888888888888888 0.107936507936508 0.05\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8888888888888888 0.107936507936508 0.06\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8962962962962963 0.10052910052910058 0.07\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8962962962962963 0.10052910052910058 0.08\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9968253968253968 0.8962962962962963 0.10052910052910058 0.09\n",
            "Best lambda for model 0 : [0.10052910052910058, 0.07]\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9907407407407407 0.920863309352518 0.06987743138822267 0.0\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.01\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.02\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.03\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.04\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.05\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.06\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.07\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.08\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9938271604938271 0.920863309352518 0.0729638511413091 0.09\n",
            "Best lambda for model 1 : [0.06987743138822267, 0.0]\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 1.0 0.8695652173913043 0.13043478260869568 0.0\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 1.0 0.8695652173913043 0.13043478260869568 0.01\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 1.0 0.8757763975155279 0.12422360248447206 0.02\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 1.0 0.8819875776397516 0.11801242236024845 0.03\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 1.0 0.8819875776397516 0.11801242236024845 0.04\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 1.0 0.8881987577639752 0.11180124223602483 0.05\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 1.0 0.8881987577639752 0.11180124223602483 0.06\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9973262032085561 0.8881987577639752 0.10912744544458097 0.07\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9973262032085561 0.8881987577639752 0.10912744544458097 0.08\n",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 \n",
            "\n",
            " 0.9973262032085561 0.8881987577639752 0.10912744544458097 0.09\n",
            "Best lambda for model 2 : [0.10912744544458097, 0.07]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_vals = [0.07, 0.0, 0.07]\n",
        "for i, model in enumerate(ber_model):\n",
        "  print(\"--------Model \"+str(i)+\"---------\")\n",
        "  for iter in range(1, 201):\n",
        "    ber_model[i] = fit(model, 0.01,lambda_vals[i])\n",
        "\n",
        "    if(iter%50 == 0):\n",
        "      acc1 = predict(model, model[\"X\"], model[\"y\"])\n",
        "      acc2 = predict(model, np_feature_vector_bernoulli_test_datasets[i], np_test_data_set_op[i])\n",
        "      print(\"Iterations Done:\", iter, end = '\\t')\n",
        "      print(\"Train Accuracy Dataset\", i, \":\", acc1, end = '\\t')\n",
        "      print(\"Test Accuracy Dataset\", i, \":\", acc2)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaHchQAaWKNm",
        "outputId": "8fa494c4-5beb-48af-a2a2-361daeef0cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------Model 0---------\n",
            "Iterations Done: 50\tTrain Accuracy Dataset 0 : 0.9866666666666667\tTest Accuracy Dataset 0 : 0.8267543859649122\n",
            "Iterations Done: 100\tTrain Accuracy Dataset 0 : 1.0\tTest Accuracy Dataset 0 : 0.8530701754385965\n",
            "Iterations Done: 150\tTrain Accuracy Dataset 0 : 1.0\tTest Accuracy Dataset 0 : 0.8508771929824561\n",
            "Iterations Done: 200\tTrain Accuracy Dataset 0 : 1.0\tTest Accuracy Dataset 0 : 0.8464912280701754\n",
            "--------Model 1---------\n",
            "Iterations Done: 50\tTrain Accuracy Dataset 1 : 0.978401727861771\tTest Accuracy Dataset 1 : 0.8368200836820083\n",
            "Iterations Done: 100\tTrain Accuracy Dataset 1 : 1.0\tTest Accuracy Dataset 1 : 0.8640167364016736\n",
            "Iterations Done: 150\tTrain Accuracy Dataset 1 : 1.0\tTest Accuracy Dataset 1 : 0.8702928870292888\n",
            "Iterations Done: 200\tTrain Accuracy Dataset 1 : 1.0\tTest Accuracy Dataset 1 : 0.8723849372384938\n",
            "--------Model 2---------\n",
            "Iterations Done: 50\tTrain Accuracy Dataset 2 : 0.994392523364486\tTest Accuracy Dataset 2 : 0.861878453038674\n",
            "Iterations Done: 100\tTrain Accuracy Dataset 2 : 1.0\tTest Accuracy Dataset 2 : 0.8766114180478821\n",
            "Iterations Done: 150\tTrain Accuracy Dataset 2 : 1.0\tTest Accuracy Dataset 2 : 0.8674033149171271\n",
            "Iterations Done: 200\tTrain Accuracy Dataset 2 : 1.0\tTest Accuracy Dataset 2 : 0.861878453038674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_analysis(model, X, y):\n",
        "  correct, wrong = 0,0\n",
        "  tp,fp,tn,fn = 0,0,0,0\n",
        "  for i, Xk in enumerate(X):\n",
        "    Xk = np.append([1], Xk)\n",
        "    sum = np.dot(model[\"weights\"], Xk)\n",
        "    t1 = sum \n",
        "    t2 = np.log(1+np.exp(sum))\n",
        "    p = np.exp(t1 - t2)\n",
        "\n",
        "    \n",
        "    if(p > 0.5 and y[i] == 1) or (p <= 0.5 and y[i] == 0): \n",
        "      correct += 1\n",
        "      if(y[i] == 0):\n",
        "        tn += 1\n",
        "      else:\n",
        "        tp += 1\n",
        "    else:\n",
        "      wrong += 1\n",
        "      if(y[i] ==0):\n",
        "        fp += 1\n",
        "      else:\n",
        "        fn += 1\n",
        "  return [correct,wrong,tp,fp,tn,fn]"
      ],
      "metadata": {
        "id": "WDwwFr52SsSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  print(\"\\nFor Bag of Words Test Dataset\",i,\":-\")\n",
        "  correct,wrong,tp,fp,tn,fn = predict_analysis(bow_model[i], np_feature_vector_bow_test_datasets[i], np_test_data_set_op[i])\n",
        "  print(\"Accuracy:\",correct/(wrong+correct))\n",
        "  print(\"F1:\",(2 * (tp/(tp+fp)) * (tp/(tp+fn))) / ((tp/(tp+fp)) + (tp/(tp+fn))))\n",
        "  print(\"Precision:\",tp/(tp+fp))\n",
        "  print(\"Recall:\",tp/(tp+fn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOQU5b7gTTPc",
        "outputId": "ccfeb027-adf8-4541-c10e-1bc5e16a7d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For Bag of Words Test Dataset 0 :-\n",
            "Accuracy: 0.8157894736842105\n",
            "F1: 0.6557377049180327\n",
            "Precision: 0.8421052631578947\n",
            "Recall: 0.5369127516778524\n",
            "\n",
            "For Bag of Words Test Dataset 1 :-\n",
            "Accuracy: 0.8368200836820083\n",
            "F1: 0.6285714285714286\n",
            "Precision: 0.825\n",
            "Recall: 0.5076923076923077\n",
            "\n",
            "For Bag of Words Test Dataset 2 :-\n",
            "Accuracy: 0.8858195211786372\n",
            "F1: 0.9221105527638191\n",
            "Precision: 0.9061728395061729\n",
            "Recall: 0.9386189258312021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  print(\"\\nFor Bernoulli Test Dataset\",i,\":-\")\n",
        "  correct,wrong,tp,fp,tn,fn = predict_analysis(ber_model[i], np_feature_vector_bernoulli_test_datasets[i], np_test_data_set_op[i])\n",
        "  print(\"Accuracy:\",correct/(wrong+correct))\n",
        "  print(\"F1:\",(2 * (tp/(tp+fp)) * (tp/(tp+fn))) / ((tp/(tp+fp)) + (tp/(tp+fn))))\n",
        "  print(\"Precision:\",tp/(tp+fp))\n",
        "  print(\"Recall:\",tp/(tp+fn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov6uNK0vbr6K",
        "outputId": "ba62e04b-3e61-4e54-f7e8-3bfb774dfc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For Bernoulli Test Dataset 0 :-\n",
            "Accuracy: 0.8464912280701754\n",
            "F1: 0.7107438016528926\n",
            "Precision: 0.9247311827956989\n",
            "Recall: 0.5771812080536913\n",
            "\n",
            "For Bernoulli Test Dataset 1 :-\n",
            "Accuracy: 0.8723849372384938\n",
            "F1: 0.7239819004524888\n",
            "Precision: 0.8791208791208791\n",
            "Recall: 0.6153846153846154\n",
            "\n",
            "For Bernoulli Test Dataset 2 :-\n",
            "Accuracy: 0.861878453038674\n",
            "F1: 0.8979591836734694\n",
            "Precision: 0.9593023255813954\n",
            "Recall: 0.8439897698209718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGD Classifier\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Fog5DlUcqXt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "model = []\n",
        "clfs = []\n",
        "for i in range(3):\n",
        "  print(\"For Bag of Words Test Dataset\",i,\":\")\n",
        "  model.append(SGDClassifier(max_iter=100))\n",
        "  clfs.append(GridSearchCV(model[i], param_grid = {'penalty' : ['l1','l2']},scoring='accuracy', cv=10))\n",
        "  clfs[i].fit(np_feature_vector_bow_train_datasets[i],np_train_data_set_op[i])\n",
        "  print(\"Tuned Hyperparameters :\", clfs[i].best_params_)\n",
        "  y_pred = clfs[i].predict(np_feature_vector_bow_test_datasets[i])\n",
        "  print(\"Accuracy:\",clfs[i].score(np_feature_vector_bow_test_datasets[i], np_test_data_set_op[i]))\n",
        "  print(precision_recall_fscore_support(np_test_data_set_op[i],y_pred,average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDbe63LkfG2N",
        "outputId": "0977e93f-c0ec-4219-842c-e4d9ee732cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Bag of Words Test Dataset 0 :\n",
            "Tuned Hyperparameters : {'penalty': 'l1'}\n",
            "Accuracy: 0.9473684210526315\n",
            "(0.9331853682028518, 0.952276851102901, 0.9415384615384614, None)\n",
            "For Bag of Words Test Dataset 1 :\n",
            "Tuned Hyperparameters : {'penalty': 'l2'}\n",
            "Accuracy: 0.9288702928870293\n",
            "(0.9101900972590629, 0.9101900972590629, 0.9101900972590629, None)\n",
            "For Bag of Words Test Dataset 2 :\n",
            "Tuned Hyperparameters : {'penalty': 'l1'}\n",
            "Accuracy: 0.9779005524861878\n",
            "(0.9805242272347536, 0.9645477184008615, 0.972134793020869, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = []\n",
        "clfs = []\n",
        "for i in range(3):\n",
        "  print(\"For Bernoulli Test Dataset\",i,\":\")\n",
        "  model.append(SGDClassifier(max_iter=100))\n",
        "  clfs.append(GridSearchCV(model[i], param_grid = {'penalty' : ['l1','l2']},scoring='accuracy', cv=10))\n",
        "  clfs[i].fit(np_feature_vector_bernoulli_train_datasets[i],np_train_data_set_op[i])\n",
        "  print(\"Tuned Hyperparameters :\", clfs[i].best_params_)\n",
        "  y_pred = clfs[i].predict(np_feature_vector_bernoulli_test_datasets[i])\n",
        "  print(\"Accuracy:\",clfs[i].score(np_feature_vector_bernoulli_test_datasets[i], np_test_data_set_op[i]))\n",
        "  print(precision_recall_fscore_support(np_test_data_set_op[i],y_pred,average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i_xjGWEUzlY",
        "outputId": "495068d4-bd27-4111-aa3d-c34d0e619a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Bernoulli Test Dataset 0 :\n",
            "Tuned Hyperparameters : {'penalty': 'l2'}\n",
            "Accuracy: 0.9407894736842105\n",
            "(0.9320915032679739, 0.9335745359945784, 0.9328266598285748, None)\n",
            "For Bernoulli Test Dataset 1 :\n",
            "Tuned Hyperparameters : {'penalty': 'l2'}\n",
            "Accuracy: 0.9581589958158996\n",
            "(0.9557469147172591, 0.9375331564986737, 0.9461129148629148, None)\n",
            "For Bernoulli Test Dataset 2 :\n",
            "Tuned Hyperparameters : {'penalty': 'l1'}\n",
            "Accuracy: 0.9631675874769797\n",
            "(0.9577830995552514, 0.9502961367613407, 0.9539440203562339, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2DbEE4dVB0F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}